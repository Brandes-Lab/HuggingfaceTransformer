{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/as12267/.conda/envs/huggingface_bert/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import wandb\n",
    "\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    PreTrainedTokenizerFast,\n",
    "    T5GemmaForConditionalGeneration,  # NOTE: PLL needs logits => use *ForConditionalGeneration*\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_initialized() -> bool:\n",
    "    return dist.is_available() and dist.is_initialized()\n",
    "\n",
    "def get_rank() -> int:\n",
    "    return dist.get_rank() if is_initialized() else 0\n",
    "\n",
    "def get_world_size() -> int:\n",
    "    return dist.get_world_size() if is_initialized() else 1\n",
    "\n",
    "def all_gather_object(gathered, local):\n",
    "    if is_initialized():\n",
    "        dist.all_gather_object(gathered, local)\n",
    "    else:\n",
    "        gathered[0] = local\n",
    "\n",
    "def maybe_init_distributed():\n",
    "    # If launched with torchrun, these env vars exist\n",
    "    if dist.is_available() and \"RANK\" in os.environ and not dist.is_initialized():\n",
    "        backend = \"nccl\" if torch.cuda.is_available() else \"gloo\"\n",
    "        dist.init_process_group(backend=backend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = \"/gpfs/data/brandeslab/model_checkpts/T5Gemma_97M_phylo_lr1e-4_bs256_ctxt_1024/checkpoint-3765\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = T5GemmaForConditionalGeneration.from_pretrained(ckpt).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phylo Tokenizer loaded. pad ID: 0\n",
      "Phylo Tokenizer loaded. GAP ID: 6\n",
      "vocab size: 27\n"
     ]
    }
   ],
   "source": [
    "from gLM.tokenizers import PhyloTokenizerLoader\n",
    "\n",
    "tokenizer = PhyloTokenizerLoader(\"./phylo_char_tokenizer_updated\")\n",
    "pad_id = tokenizer.pad_token_id\n",
    "gap_id = tokenizer.convert_tokens_to_ids(\"-\")\n",
    "print(\"Phylo Tokenizer loaded. pad ID:\", pad_id)\n",
    "print(\"Phylo Tokenizer loaded. GAP ID:\", gap_id)\n",
    "print(f\"vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>label</th>\n",
       "      <th>seq_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSYYGNYYGGLGYGYDCKYSYTSGFGAFRILDCGYRCGCGGVWI</td>\n",
       "      <td>8</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MKFFVFALILALMLSMTGADSHAKRHHGYKRKFHEKHHSHRGYRSN...</td>\n",
       "      <td>16</td>\n",
       "      <td>T</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MVAYWRQAGLSYIRYSQICAKAVRDALKTEFKANAEKTSGSNVKIV...</td>\n",
       "      <td>28</td>\n",
       "      <td>T</td>\n",
       "      <td>K</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCYGYGCGCGSFCRLGYGCGYEGCRYGCGHRGCGDGCCCPSCYRRY...</td>\n",
       "      <td>48</td>\n",
       "      <td>T</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCSYYHMKKRSVSGCNITIFAVMFSHLSAGKSPCGNQANVLCISRL...</td>\n",
       "      <td>12</td>\n",
       "      <td>S</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MCTTLFLLSTLAMLWRRRFANRVQPEPSDVDGAARGSSLDADPQSS...</td>\n",
       "      <td>16</td>\n",
       "      <td>R</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MCTTLFLLSTLAMLWRRRFANRVQPEPSDVDGAARGSSLDADPQSS...</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MVKLSKEAKQRLQQLFKGSQFAIRWGFIPLVIYLGFKRGADPGMPE...</td>\n",
       "      <td>24</td>\n",
       "      <td>W</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  pos ref alt  label  \\\n",
       "0       MSYYGNYYGGLGYGYDCKYSYTSGFGAFRILDCGYRCGCGGVWI    8   G   R      0   \n",
       "1  MKFFVFALILALMLSMTGADSHAKRHHGYKRKFHEKHHSHRGYRSN...   16   T   I      0   \n",
       "2  MVAYWRQAGLSYIRYSQICAKAVRDALKTEFKANAEKTSGSNVKIV...   28   T   K      0   \n",
       "3  MCYGYGCGCGSFCRLGYGCGYEGCRYGCGHRGCGDGCCCPSCYRRY...   48   T   S      0   \n",
       "4  MCSYYHMKKRSVSGCNITIFAVMFSHLSAGKSPCGNQANVLCISRL...   12   S   L      0   \n",
       "5  MCTTLFLLSTLAMLWRRRFANRVQPEPSDVDGAARGSSLDADPQSS...   16   R   C      0   \n",
       "6  MCTTLFLLSTLAMLWRRRFANRVQPEPSDVDGAARGSSLDADPQSS...    0   M   T      1   \n",
       "7  MVKLSKEAKQRLQQLFKGSQFAIRWGFIPLVIYLGFKRGADPGMPE...   24   W   R      1   \n",
       "\n",
       "   seq_length  \n",
       "0          44  \n",
       "1          51  \n",
       "2          51  \n",
       "3          52  \n",
       "4          53  \n",
       "5          54  \n",
       "6          54  \n",
       "7          55  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clin_var = pd.read_csv(\"/gpfs/data/brandeslab/Data/clinvar_AA_zero_shot_input.csv\")\n",
    "clin_var['seq_length'] = clin_var['sequence'].str.len()\n",
    "# bottom 8 seqeunces \n",
    "bottom_8 = clin_var.sort_values('seq_length', ascending=True).reset_index(drop=True).head(8)\n",
    "\n",
    "bottom_8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottom_8_tok shape torch.Size([8, 55])\n",
      "decoder_start_id 0\n",
      "decoder_input_ids shape torch.Size([8, 55])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 17, 22, 26, 26, 12, 18, 26, 26, 12, 12, 16, 12, 26, 12, 26,  9,  8,\n",
       "         15, 26, 22, 26, 23, 22, 12, 11, 12,  7, 11, 21, 14, 16,  9,  8, 12, 26,\n",
       "         21,  8, 12,  8, 12, 12, 24, 25, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0],\n",
       "        [ 0, 17, 15, 11, 11, 24, 11,  7, 16, 14, 16,  7, 16, 17, 16, 22, 17, 23,\n",
       "         12,  7,  9, 22, 13,  7, 15, 21, 13, 13, 12, 26, 15, 21, 15, 11, 13, 10,\n",
       "         15, 13, 13, 22, 13, 21, 12, 26, 21, 22, 18, 26, 16, 26,  9, 18,  0,  0,\n",
       "          0],\n",
       "        [ 0, 17, 24,  7, 26, 25, 21, 20,  7, 12, 16, 22, 26, 14, 21, 26, 22, 20,\n",
       "         14,  8,  7, 15,  7, 24, 21,  9,  7, 16, 15, 23, 10, 11, 15,  7, 18,  7,\n",
       "         10, 15, 23, 22, 12, 22, 18, 24, 15, 14, 24, 15, 24, 15, 15, 10,  0,  0,\n",
       "          0],\n",
       "        [ 0, 17,  8, 26, 12, 26, 12,  8, 12,  8, 12, 22, 11,  8, 21, 16, 12, 26,\n",
       "         12,  8, 12, 26, 10, 12,  8, 21, 26, 12,  8, 12, 13, 21, 12,  8, 12,  9,\n",
       "         12,  8,  8,  8, 19, 22,  8, 26, 21, 21, 26, 21, 11, 23, 12, 11, 26,  0,\n",
       "          0],\n",
       "        [ 0, 17,  8, 22, 26, 26, 13, 17, 15, 15, 21, 22, 24, 22, 12,  8, 18, 14,\n",
       "         23, 14, 11,  7, 24, 17, 11, 22, 13, 16, 22,  7, 12, 15, 22, 19,  8, 12,\n",
       "         18, 20,  7, 18, 24, 16,  8, 14, 22, 21, 16, 10, 11, 24, 20, 26, 20, 22,\n",
       "          0],\n",
       "        [ 0, 17,  8, 23, 23, 16, 11, 16, 16, 22, 23, 16,  7, 17, 16, 25, 21, 21,\n",
       "         21, 11,  7, 18, 21, 24, 20, 19, 10, 19, 22,  9, 24,  9, 12,  7,  7, 21,\n",
       "         12, 22, 22, 16,  9,  7,  9, 19, 20, 22, 22, 12, 21, 10, 15, 10, 19, 16,\n",
       "         15],\n",
       "        [ 0, 17,  8, 23, 23, 16, 11, 16, 16, 22, 23, 16,  7, 17, 16, 25, 21, 21,\n",
       "         21, 11,  7, 18, 21, 24, 20, 19, 10, 19, 22,  9, 24,  9, 12,  7,  7, 21,\n",
       "         12, 22, 22, 16,  9,  7,  9, 19, 20, 22, 22, 12, 21, 10, 15, 10, 19, 16,\n",
       "         15],\n",
       "        [ 0, 17, 24, 15, 16, 22, 15, 10,  7, 15, 20, 21, 16, 20, 20, 16, 11, 15,\n",
       "         12, 22, 20, 11,  7, 14, 21, 25, 12, 11, 14, 19, 16, 24, 14, 26, 16, 12,\n",
       "         11, 15, 21, 12,  7,  9, 19, 12, 17, 19, 10, 19, 23, 24, 16, 22, 16, 16,\n",
       "         25]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shift_right(input_ids: torch.Tensor, start_id: int, pad_id: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    \n",
    "    Build decoder inputs for teacher forcing (autoregressive decoding).\n",
    "\n",
    "    We want the decoder to predict token t using only tokens < t as context.\n",
    "    So we create a \"shifted-right\" version of the target sequence:\n",
    "\n",
    "      - Same shape in/out: [B, T]\n",
    "      - The first decoder input is a special start token (decoder_start_token_id)\n",
    "      - Everything else is the target sequence shifted right by 1 position\n",
    "\n",
    "    Concretely, for a target sequence y = [y0, y1, ..., y(T-1)]:\n",
    "\n",
    "      decoder_input_ids = [<start>, y0, y1, ..., y(T-2)]   # length T\n",
    "      labels            = [y0,      y1, y2, ..., y(T-1)]   # length T\n",
    "\n",
    "    This keeps decoder_input_ids and labels aligned in time:\n",
    "    logits[:, t] corresponds to predicting labels[:, t] given decoder_input_ids[:, :t].\n",
    "\n",
    "    input_ids: LongTensor [B, T]\n",
    "    returns:   LongTensor [B, T]\n",
    "      out[:,0] = start_id\n",
    "      out[:,1:] = input_ids[:,:-1]\n",
    "    \"\"\"\n",
    "    B, T = input_ids.shape\n",
    "    shifted = input_ids.new_zeros((B, T))\n",
    "    # print(\"shifted\", shifted)\n",
    "    shifted[:, 0] = start_id\n",
    "    # print(\"shifted after setting start_id\", shifted)\n",
    "    shifted[:, 1:] = input_ids[:, :-1]\n",
    "    # print(\"shifted after shifting\", shifted)\n",
    "    # shifted = shifted.masked_fill(shifted == -100, pad_id)\n",
    "    # print(\"shifted after masking -100 with pad_id\", shifted)\n",
    "    return shifted\n",
    "\n",
    "bottom_8_tok = tokenizer(\n",
    "    bottom_8['sequence'].tolist(),\n",
    "    padding='longest',\n",
    "    truncation=True,\n",
    "    max_length=1024,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "bottom_8_tok\n",
    "print(\"bottom_8_tok shape\", bottom_8_tok['input_ids'].shape) # [8, 55]\n",
    "\n",
    "decoder_start_id = getattr(model.config, \"decoder_start_token_id\", None)\n",
    "print(\"decoder_start_id\", decoder_start_id) \n",
    "\n",
    "decoder_input_ids = shift_right(bottom_8_tok['input_ids'], decoder_start_id, pad_id)\n",
    "print(\"decoder_input_ids shape\", decoder_input_ids.shape) \n",
    "decoder_input_ids\n",
    "\n",
    "# single_tok = tokenizer(\n",
    "#     bottom_8.loc[1, \"sequence\"],   # or bottom_8[\"sequence\"].iloc[1]\n",
    "#     padding='longest',\n",
    "#     truncation=True,\n",
    "#     max_length=1024,\n",
    "#     return_tensors='pt'\n",
    "# )\n",
    "\n",
    "\n",
    "# single_tok\n",
    "# print(\"single_tok_tok shape\", single_tok['input_ids'].shape) # [8, 55]\n",
    "\n",
    "# decoder_start_id = getattr(model.config, \"decoder_start_token_id\", None)\n",
    "# print(\"decoder_start_id\", decoder_start_id) \n",
    "\n",
    "# decoder_input_ids = shift_right(single_tok['input_ids'], decoder_start_id, pad_id)\n",
    "# print(\"decoder_input_ids shape\", decoder_input_ids.shape) \n",
    "# decoder_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[17, 15, 11, 11, 24, 11,  7, 16, 14, 16,  7, 16, 17, 16, 22, 17, 23, 12,\n",
       "          7,  9, 22, 13,  7, 15, 21, 13, 13, 12, 26, 15, 21, 15, 11, 13, 10, 15,\n",
       "         13, 13, 22, 13, 21, 12, 26, 21, 22, 18, 26, 16, 26,  9, 18]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_tok = tokenizer(\n",
    "    bottom_8.loc[1, \"sequence\"],   # or bottom_8[\"sequence\"].iloc[1]\n",
    "    padding='longest',\n",
    "    truncation=True,\n",
    "    max_length=1024,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "single_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17, 22, 26, 26, 12, 18, 26, 26, 12, 12, 16, 12, 26, 12, 26,  9,  8, 15,\n",
       "         26, 22, 26, 23, 22, 12, 11, 12,  7, 11, 21, 14, 16,  9,  8, 12, 26, 21,\n",
       "          8, 12,  8, 12, 12, 24, 25, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0],\n",
       "        [17, 15, 11, 11, 24, 11,  7, 16, 14, 16,  7, 16, 17, 16, 22, 17, 23, 12,\n",
       "          7,  9, 22, 13,  7, 15, 21, 13, 13, 12, 26, 15, 21, 15, 11, 13, 10, 15,\n",
       "         13, 13, 22, 13, 21, 12, 26, 21, 22, 18, 26, 16, 26,  9, 18,  0,  0,  0,\n",
       "          0],\n",
       "        [17, 24,  7, 26, 25, 21, 20,  7, 12, 16, 22, 26, 14, 21, 26, 22, 20, 14,\n",
       "          8,  7, 15,  7, 24, 21,  9,  7, 16, 15, 23, 10, 11, 15,  7, 18,  7, 10,\n",
       "         15, 23, 22, 12, 22, 18, 24, 15, 14, 24, 15, 24, 15, 15, 10,  0,  0,  0,\n",
       "          0],\n",
       "        [17,  8, 26, 12, 26, 12,  8, 12,  8, 12, 22, 11,  8, 21, 16, 12, 26, 12,\n",
       "          8, 12, 26, 10, 12,  8, 21, 26, 12,  8, 12, 13, 21, 12,  8, 12,  9, 12,\n",
       "          8,  8,  8, 19, 22,  8, 26, 21, 21, 26, 21, 11, 23, 12, 11, 26,  0,  0,\n",
       "          0],\n",
       "        [17,  8, 22, 26, 26, 13, 17, 15, 15, 21, 22, 24, 22, 12,  8, 18, 14, 23,\n",
       "         14, 11,  7, 24, 17, 11, 22, 13, 16, 22,  7, 12, 15, 22, 19,  8, 12, 18,\n",
       "         20,  7, 18, 24, 16,  8, 14, 22, 21, 16, 10, 11, 24, 20, 26, 20, 22,  0,\n",
       "          0],\n",
       "        [17,  8, 23, 23, 16, 11, 16, 16, 22, 23, 16,  7, 17, 16, 25, 21, 21, 21,\n",
       "         11,  7, 18, 21, 24, 20, 19, 10, 19, 22,  9, 24,  9, 12,  7,  7, 21, 12,\n",
       "         22, 22, 16,  9,  7,  9, 19, 20, 22, 22, 12, 21, 10, 15, 10, 19, 16, 15,\n",
       "          0],\n",
       "        [17,  8, 23, 23, 16, 11, 16, 16, 22, 23, 16,  7, 17, 16, 25, 21, 21, 21,\n",
       "         11,  7, 18, 21, 24, 20, 19, 10, 19, 22,  9, 24,  9, 12,  7,  7, 21, 12,\n",
       "         22, 22, 16,  9,  7,  9, 19, 20, 22, 22, 12, 21, 10, 15, 10, 19, 16, 15,\n",
       "          0],\n",
       "        [17, 24, 15, 16, 22, 15, 10,  7, 15, 20, 21, 16, 20, 20, 16, 11, 15, 12,\n",
       "         22, 20, 11,  7, 14, 21, 25, 12, 11, 14, 19, 16, 24, 14, 26, 16, 12, 11,\n",
       "         15, 21, 12,  7,  9, 19, 12, 17, 19, 10, 19, 23, 24, 16, 22, 16, 16, 25,\n",
       "         12]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_8_tok['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def pll_batch_seq2seq(model, tokenizer, seqs: List[str], max_len: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    PLL(s) = sum_t log P(s_t | s_<t, encoder(s)) for each sequence.\n",
    "    Returns: FloatTensor [B]\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # tok = tokenizer(\n",
    "    #     list(seqs),\n",
    "    #     return_tensors=\"pt\",\n",
    "    #     padding=\"longest\",\n",
    "    #     truncation=True,\n",
    "    #     max_length=max_len,\n",
    "    #     add_special_tokens=False,\n",
    "    # ).to(device)\n",
    "    tok = tokenizer(\n",
    "        seqs,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        add_special_tokens=False,\n",
    "    ).to(device)\n",
    "\n",
    "    input_ids = tok[\"input_ids\"]            # [B, T]\n",
    "    attention_mask = tok[\"attention_mask\"]  # [B, T]\n",
    "\n",
    "    labels = input_ids.clone()\n",
    "    labels = labels.masked_fill(attention_mask == 0, -100)\n",
    "    print(\"encoder inputs shape\", input_ids.shape)\n",
    "    print(input_ids)\n",
    "    print(\"encoder attention mask shape\", attention_mask.shape)\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "    enc_sum_expected = (input_ids != pad_id).sum()\n",
    "    # Encoder mask sum equals the total number of non-pad tokens in input_ids\n",
    "    print(\"enc_sum expected:\", enc_sum_expected.item())\n",
    "    print(\"enc_sum actual:  \", attention_mask.sum().item())\n",
    "\n",
    "    print(\"labels shape\", labels.shape)\n",
    "\n",
    "    decoder_start_id = getattr(model.config, \"decoder_start_token_id\", None)\n",
    "    if decoder_start_id is None:\n",
    "        decoder_start_id = tokenizer.pad_token_id\n",
    "\n",
    "    decoder_input_ids = shift_right(input_ids, decoder_start_id, tokenizer.pad_token_id)  # [B,T]\n",
    "    print(\"decoder_input_ids shape\", decoder_input_ids.shape)\n",
    "    decoder_attention_mask = shift_right(attention_mask, 1, 0)                            # [B,T]\n",
    "    print(\"decoder_attention_mask shape\", decoder_attention_mask.shape)\n",
    "    print(\"decoder_attention_mask_sum\", decoder_attention_mask.sum()) # decoder_sum=encoder_sum+B−#(rows where last token is real)\n",
    "    B, T = attention_mask.shape\n",
    "\n",
    "    last_is_real = attention_mask[:, -1].sum().item()     # how many rows have a real token at last column\n",
    "    dec_sum_expected = attention_mask.sum().item() + B - last_is_real\n",
    "\n",
    "    print(\"B:\", B)\n",
    "    print(\"last_is_real rows:\", last_is_real)\n",
    "    print(\"dec_sum expected:\", dec_sum_expected)\n",
    "    print(\"dec_sum actual:  \", decoder_attention_mask.sum().item())\n",
    "\n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        decoder_input_ids=decoder_input_ids,\n",
    "        decoder_attention_mask=decoder_attention_mask,\n",
    "    )\n",
    "\n",
    "    logits = outputs.logits                 # [B, T, V]  <-- requires *ForConditionalGeneration*\n",
    "    print(\"logits shape\", logits.shape)\n",
    "    # print(\"logits\", logits)\n",
    "    log_probs = F.log_softmax(logits, -1)   # [B, T, V]\n",
    "    print(\"log_probs shape\", log_probs.shape)\n",
    "    # print(\"log_probs\", log_probs)\n",
    "\n",
    "    gather_labels = labels.clone()\n",
    "    gather_labels[gather_labels == -100] = 0\n",
    "    print(\"gather_labels shape\", gather_labels.shape)\n",
    "    # print(\"gather_labels\", gather_labels)\n",
    "\n",
    "    token_logp = log_probs.gather(\n",
    "        dim=-1, index=gather_labels.unsqueeze(-1)  # [B, T, 1]\n",
    "    ).squeeze(-1)                                   # [B, T]\n",
    "    print(\"token_logp shape\", token_logp.shape)\n",
    "    # print(\"token_logp\", token_logp)\n",
    "    token_logp = token_logp * (labels != -100).to(token_logp.dtype)  # [B, T]\n",
    "    print(\"token_logp after masking shape\", token_logp.shape)\n",
    "    # print(\"token_logp after masking\", token_logp)\n",
    "    sum = token_logp.sum(dim=1) # B\n",
    "    print(\"sum shape\", sum.shape)\n",
    "    # print(\"sum\", sum)\n",
    "    return sum # [B]\n",
    "    \n",
    "\n",
    "# bottom_8_pll = pll_batch_seq2seq(model, tokenizer, bottom_8['sequence'].tolist(), max_len=1024)\n",
    "\n",
    "# single_tok_pll = pll_batch_seq2seq(model, tokenizer, bottom_8.loc[7, \"sequence\"], max_len=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def pll_batch_seq2seq_conditional(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    encoder_seqs: List[str],\n",
    "    target_seqs: List[str],\n",
    "    max_len: int,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute PLL(target | encoder) in batch.\n",
    "\n",
    "    PLL = sum_t log P(target_t | target_<t, encoder(encoder_seq))\n",
    "\n",
    "    encoder_seqs: list[str] length B\n",
    "    target_seqs:  list[str] length B\n",
    "    returns: FloatTensor [B]\n",
    "    \"\"\"\n",
    "    assert len(encoder_seqs) == len(target_seqs), \"encoder_seqs and target_seqs must match length\"\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # --- tokenize encoder side ---\n",
    "    enc = tokenizer(\n",
    "        encoder_seqs,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        add_special_tokens=False,\n",
    "    ).to(device)\n",
    "    enc_input_ids = enc[\"input_ids\"]              # [B, Tenc]\n",
    "    enc_attention_mask = enc[\"attention_mask\"]    # [B, Tenc]\n",
    "\n",
    "    # --- tokenize decoder/target side ---\n",
    "    dec = tokenizer(\n",
    "        target_seqs,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        add_special_tokens=False,\n",
    "    ).to(device)\n",
    "    tgt_input_ids = dec[\"input_ids\"]              # [B, Tdec]\n",
    "    tgt_attention_mask = dec[\"attention_mask\"]    # [B, Tdec]\n",
    "\n",
    "    # labels: ignore pad positions in the loss / gathering\n",
    "    labels = tgt_input_ids.clone()\n",
    "    labels = labels.masked_fill(tgt_attention_mask == 0, -100)  # [B, Tdec]\n",
    "\n",
    "    decoder_start_id = getattr(model.config, \"decoder_start_token_id\", None)\n",
    "    if decoder_start_id is None:\n",
    "        decoder_start_id = tokenizer.pad_token_id\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "\n",
    "    decoder_input_ids = shift_right(tgt_input_ids, decoder_start_id, pad_id)  # [B, Tdec]\n",
    "\n",
    "    # decoder attention: 1 for positions the decoder is allowed to attend to.\n",
    "    # We want the \"start\" position to be attended, and pads to be off.\n",
    "    decoder_attention_mask = shift_right(tgt_attention_mask, 1, 0)            # [B, Tdec]\n",
    "\n",
    "    outputs = model(\n",
    "        input_ids=enc_input_ids,\n",
    "        attention_mask=enc_attention_mask,\n",
    "        decoder_input_ids=decoder_input_ids,\n",
    "        decoder_attention_mask=decoder_attention_mask,\n",
    "    )\n",
    "\n",
    "    logits = outputs.logits                         # [B, Tdec, V]\n",
    "    log_probs = F.log_softmax(logits, dim=-1)       # [B, Tdec, V]\n",
    "\n",
    "    # gather log prob of the true token at each position\n",
    "    gather_labels = labels.clone()\n",
    "    gather_labels[gather_labels == -100] = 0        # safe index for gather\n",
    "    token_logp = log_probs.gather(\n",
    "        dim=-1, index=gather_labels.unsqueeze(-1)   # [B, Tdec, 1]\n",
    "    ).squeeze(-1)                                   # [B, Tdec]\n",
    "\n",
    "    # zero out pad positions (where labels == -100)\n",
    "    token_logp = token_logp * (labels != -100).to(token_logp.dtype)\n",
    "\n",
    "    return token_logp.sum(dim=1)                    # [B]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bottom_8.loc[1, \"sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation:\n",
    "# For the 7 sequences shorter than 55, the last column was PAD (0) in the encoder mask, so when you shift-right and insert a start token mask 1, you gain +1 per such row.\n",
    "# For the 1 sequence of length 55, the last column was already real (1), so shifting drops that 1 but adds the start 1 → net 0 change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder inputs shape torch.Size([8, 55])\n",
      "tensor([[17, 22, 26, 26, 12, 18, 26, 26, 12, 12, 16, 12, 26, 12, 26,  9,  8, 15,\n",
      "         26, 22, 26, 23, 22, 12, 11, 12,  7, 11, 21, 14, 16,  9,  8, 12, 26, 21,\n",
      "          8, 12,  8, 12, 12, 24, 25, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [17, 15, 11, 11, 24, 11,  7, 16, 14, 16,  7, 16, 17, 16, 22, 17, 23, 12,\n",
      "          7,  9, 22, 13,  7, 15, 21, 13, 13, 12, 26, 15, 21, 15, 11, 13, 10, 15,\n",
      "         13, 13, 22, 13, 21, 12, 26, 21, 22, 18, 26, 16, 26,  9, 18,  0,  0,  0,\n",
      "          0],\n",
      "        [17, 24,  7, 26, 25, 21, 20,  7, 12, 16, 22, 26, 14, 21, 26, 22, 20, 14,\n",
      "          8,  7, 15,  7, 24, 21,  9,  7, 16, 15, 23, 10, 11, 15,  7, 18,  7, 10,\n",
      "         15, 23, 22, 12, 22, 18, 24, 15, 14, 24, 15, 24, 15, 15, 10,  0,  0,  0,\n",
      "          0],\n",
      "        [17,  8, 26, 12, 26, 12,  8, 12,  8, 12, 22, 11,  8, 21, 16, 12, 26, 12,\n",
      "          8, 12, 26, 10, 12,  8, 21, 26, 12,  8, 12, 13, 21, 12,  8, 12,  9, 12,\n",
      "          8,  8,  8, 19, 22,  8, 26, 21, 21, 26, 21, 11, 23, 12, 11, 26,  0,  0,\n",
      "          0],\n",
      "        [17,  8, 22, 26, 26, 13, 17, 15, 15, 21, 22, 24, 22, 12,  8, 18, 14, 23,\n",
      "         14, 11,  7, 24, 17, 11, 22, 13, 16, 22,  7, 12, 15, 22, 19,  8, 12, 18,\n",
      "         20,  7, 18, 24, 16,  8, 14, 22, 21, 16, 10, 11, 24, 20, 26, 20, 22,  0,\n",
      "          0],\n",
      "        [17,  8, 23, 23, 16, 11, 16, 16, 22, 23, 16,  7, 17, 16, 25, 21, 21, 21,\n",
      "         11,  7, 18, 21, 24, 20, 19, 10, 19, 22,  9, 24,  9, 12,  7,  7, 21, 12,\n",
      "         22, 22, 16,  9,  7,  9, 19, 20, 22, 22, 12, 21, 10, 15, 10, 19, 16, 15,\n",
      "          0],\n",
      "        [17,  8, 23, 23, 16, 11, 16, 16, 22, 23, 16,  7, 17, 16, 25, 21, 21, 21,\n",
      "         11,  7, 18, 21, 24, 20, 19, 10, 19, 22,  9, 24,  9, 12,  7,  7, 21, 12,\n",
      "         22, 22, 16,  9,  7,  9, 19, 20, 22, 22, 12, 21, 10, 15, 10, 19, 16, 15,\n",
      "          0],\n",
      "        [17, 24, 15, 16, 22, 15, 10,  7, 15, 20, 21, 16, 20, 20, 16, 11, 15, 12,\n",
      "         22, 20, 11,  7, 14, 21, 25, 12, 11, 14, 19, 16, 24, 14, 26, 16, 12, 11,\n",
      "         15, 21, 12,  7,  9, 19, 12, 17, 19, 10, 19, 23, 24, 16, 22, 16, 16, 25,\n",
      "         12]], device='cuda:0')\n",
      "encoder attention mask shape torch.Size([8, 55])\n",
      "enc_sum expected: 414\n",
      "enc_sum actual:   414\n",
      "labels shape torch.Size([8, 55])\n",
      "decoder_input_ids shape torch.Size([8, 55])\n",
      "decoder_attention_mask shape torch.Size([8, 55])\n",
      "decoder_attention_mask_sum tensor(421, device='cuda:0')\n",
      "B: 8\n",
      "last_is_real rows: 1\n",
      "dec_sum expected: 421\n",
      "dec_sum actual:   421\n",
      "logits shape torch.Size([8, 55, 27])\n",
      "log_probs shape torch.Size([8, 55, 27])\n",
      "gather_labels shape torch.Size([8, 55])\n",
      "token_logp shape torch.Size([8, 55])\n",
      "token_logp after masking shape torch.Size([8, 55])\n",
      "sum shape torch.Size([8])\n",
      "wt_pll tensor([-1.3110, -2.0651, -2.0240, -3.4934, -1.9489, -2.2246, -2.2246, -2.0945],\n",
      "       device='cuda:0')\n",
      "encoder inputs shape torch.Size([8, 55])\n",
      "tensor([[17, 22, 26, 26, 12, 18, 26, 26, 21, 12, 16, 12, 26, 12, 26,  9,  8, 15,\n",
      "         26, 22, 26, 23, 22, 12, 11, 12,  7, 11, 21, 14, 16,  9,  8, 12, 26, 21,\n",
      "          8, 12,  8, 12, 12, 24, 25, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0],\n",
      "        [17, 15, 11, 11, 24, 11,  7, 16, 14, 16,  7, 16, 17, 16, 22, 17, 14, 12,\n",
      "          7,  9, 22, 13,  7, 15, 21, 13, 13, 12, 26, 15, 21, 15, 11, 13, 10, 15,\n",
      "         13, 13, 22, 13, 21, 12, 26, 21, 22, 18, 26, 16, 26,  9, 18,  0,  0,  0,\n",
      "          0],\n",
      "        [17, 24,  7, 26, 25, 21, 20,  7, 12, 16, 22, 26, 14, 21, 26, 22, 20, 14,\n",
      "          8,  7, 15,  7, 24, 21,  9,  7, 16, 15, 15, 10, 11, 15,  7, 18,  7, 10,\n",
      "         15, 23, 22, 12, 22, 18, 24, 15, 14, 24, 15, 24, 15, 15, 10,  0,  0,  0,\n",
      "          0],\n",
      "        [17,  8, 26, 12, 26, 12,  8, 12,  8, 12, 22, 11,  8, 21, 16, 12, 26, 12,\n",
      "          8, 12, 26, 10, 12,  8, 21, 26, 12,  8, 12, 13, 21, 12,  8, 12,  9, 12,\n",
      "          8,  8,  8, 19, 22,  8, 26, 21, 21, 26, 21, 11, 22, 12, 11, 26,  0,  0,\n",
      "          0],\n",
      "        [17,  8, 22, 26, 26, 13, 17, 15, 15, 21, 22, 24, 16, 12,  8, 18, 14, 23,\n",
      "         14, 11,  7, 24, 17, 11, 22, 13, 16, 22,  7, 12, 15, 22, 19,  8, 12, 18,\n",
      "         20,  7, 18, 24, 16,  8, 14, 22, 21, 16, 10, 11, 24, 20, 26, 20, 22,  0,\n",
      "          0],\n",
      "        [17,  8, 23, 23, 16, 11, 16, 16, 22, 23, 16,  7, 17, 16, 25, 21,  8, 21,\n",
      "         11,  7, 18, 21, 24, 20, 19, 10, 19, 22,  9, 24,  9, 12,  7,  7, 21, 12,\n",
      "         22, 22, 16,  9,  7,  9, 19, 20, 22, 22, 12, 21, 10, 15, 10, 19, 16, 15,\n",
      "          0],\n",
      "        [23,  8, 23, 23, 16, 11, 16, 16, 22, 23, 16,  7, 17, 16, 25, 21, 21, 21,\n",
      "         11,  7, 18, 21, 24, 20, 19, 10, 19, 22,  9, 24,  9, 12,  7,  7, 21, 12,\n",
      "         22, 22, 16,  9,  7,  9, 19, 20, 22, 22, 12, 21, 10, 15, 10, 19, 16, 15,\n",
      "          0],\n",
      "        [17, 24, 15, 16, 22, 15, 10,  7, 15, 20, 21, 16, 20, 20, 16, 11, 15, 12,\n",
      "         22, 20, 11,  7, 14, 21, 21, 12, 11, 14, 19, 16, 24, 14, 26, 16, 12, 11,\n",
      "         15, 21, 12,  7,  9, 19, 12, 17, 19, 10, 19, 23, 24, 16, 22, 16, 16, 25,\n",
      "         12]], device='cuda:0')\n",
      "encoder attention mask shape torch.Size([8, 55])\n",
      "enc_sum expected: 414\n",
      "enc_sum actual:   414\n",
      "labels shape torch.Size([8, 55])\n",
      "decoder_input_ids shape torch.Size([8, 55])\n",
      "decoder_attention_mask shape torch.Size([8, 55])\n",
      "decoder_attention_mask_sum tensor(421, device='cuda:0')\n",
      "B: 8\n",
      "last_is_real rows: 1\n",
      "dec_sum expected: 421\n",
      "dec_sum actual:   421\n",
      "logits shape torch.Size([8, 55, 27])\n",
      "log_probs shape torch.Size([8, 55, 27])\n",
      "gather_labels shape torch.Size([8, 55])\n",
      "token_logp shape torch.Size([8, 55])\n",
      "token_logp after masking shape torch.Size([8, 55])\n",
      "sum shape torch.Size([8])\n",
      "mut_pll tensor([-1.3583, -2.1203, -1.9995, -3.1167, -1.9778, -2.1648, -4.7039, -2.0682],\n",
      "       device='cuda:0')\n",
      "[-0.047315239906311035, -0.055260419845581055, 0.024501562118530273, 0.3767085075378418, -0.028808116912841797, 0.05974912643432617, -2.479379177093506, 0.02633070945739746]\n",
      "-0.047315239906311035\n"
     ]
    }
   ],
   "source": [
    "def compute_pll_diff_encoder_decoder(model, tokenizer, seqs, poses, refs, alts, max_len: int):\n",
    "    \"\"\"\n",
    "    ΔPLL = PLL(mut) - PLL(wt)\n",
    "    Returns: list[float|None] aligned to input order\n",
    "    \"\"\"\n",
    "    results = [None] * len(seqs)\n",
    "    valid_data = []\n",
    "\n",
    "    for i, (seq, pos, ref, alt) in enumerate(zip(seqs, poses, refs, alts)):\n",
    "        if len(seq) <= max_len and 0 <= pos < len(seq) and seq[pos] == ref:\n",
    "            ref_id = tokenizer.convert_tokens_to_ids(ref)\n",
    "            alt_id = tokenizer.convert_tokens_to_ids(alt)\n",
    "            if ref_id is None or alt_id is None:\n",
    "                continue\n",
    "            valid_data.append((i, seq, pos, alt))\n",
    "\n",
    "    if not valid_data:\n",
    "        return results\n",
    "\n",
    "    indices = [x[0] for x in valid_data]\n",
    "    wt_seqs  = [x[1] for x in valid_data]\n",
    "    poses_v  = [x[2] for x in valid_data]\n",
    "    alts_v   = [x[3] for x in valid_data]\n",
    "\n",
    "    mut_seqs = [wt[:pos] + alt + wt[pos + 1:] for wt, pos, alt in zip(wt_seqs, poses_v, alts_v)]\n",
    "\n",
    "    wt_pll  = pll_batch_seq2seq(model, tokenizer, wt_seqs,  max_len=max_len)  # [B]\n",
    "    print(\"wt_pll\", wt_pll)\n",
    "    mut_pll = pll_batch_seq2seq(model, tokenizer, mut_seqs, max_len=max_len)  # [B]\n",
    "    print(\"mut_pll\", mut_pll)\n",
    "\n",
    "\n",
    "    delta = (mut_pll - wt_pll).tolist()\n",
    "    for idx, d in zip(indices, delta):\n",
    "        results[idx] = float(d)\n",
    "    return results\n",
    "\n",
    "# delta_pll_results = compute_pll_diff_encoder_decoder(\n",
    "#     model, tokenizer,\n",
    "#     seqs=[bottom_8.loc[7, \"sequence\"]],\n",
    "#     poses=[int(bottom_8.loc[7, \"pos\"])],   # make sure it's int\n",
    "#     refs=[bottom_8.loc[7, \"ref\"]],\n",
    "#     alts=[bottom_8.loc[7, \"alt\"]],\n",
    "#     max_len=1024\n",
    "# )\n",
    "\n",
    "# print(delta_pll_results)        # list aligned to input order (length 1)\n",
    "# print(delta_pll_results[0])     # the scalar delta PLL\n",
    "\n",
    "\n",
    "delta_pll_results = compute_pll_diff_encoder_decoder(\n",
    "    model, tokenizer,\n",
    "    seqs=bottom_8['sequence'].tolist(),  # convert tensor to list of lists\n",
    "    poses=bottom_8[\"pos\"].tolist(),   # make sure it's int\n",
    "    refs=bottom_8[\"ref\"].tolist(),\n",
    "    alts=bottom_8[\"alt\"].tolist(),\n",
    "    max_len=1024\n",
    ")\n",
    "\n",
    "print(delta_pll_results)        # list aligned to input order (length 1)\n",
    "print(delta_pll_results[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'V', 'K', 'L', 'S', 'K', 'E', 'A', 'K', 'Q', 'R', 'L', 'Q', 'Q', 'L', 'F', 'K', 'G', 'S', 'Q', 'F', 'A', 'I', 'R', 'W', 'G', 'F', 'I', 'P', 'L', 'V', 'I', 'Y', 'L', 'G', 'F', 'K', 'R', 'G', 'A', 'D', 'P', 'G', 'M', 'P', 'E', 'P', 'T', 'V', 'L', 'S', 'L', 'L', 'W', 'G']\n",
      "24\n",
      "['W']\n",
      "['R']\n"
     ]
    }
   ],
   "source": [
    "print(list(bottom_8.loc[7, \"sequence\"]))\n",
    "print(bottom_8.loc[7, \"pos\"])\n",
    "print(list(bottom_8.loc[7, 'ref']))\n",
    "print(list(bottom_8.loc[7,'alt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_vep_eval(df: pd.DataFrame, model, tokenizer, batch_size: int, max_len: int, step_id: int, log_wandb: bool):\n",
    "    rank = get_rank()\n",
    "    world_size = get_world_size()\n",
    "    print(f\"[Rank {rank}] Starting PLL VEP eval @ step {step_id}\", flush=True)\n",
    "\n",
    "    seqs = df[\"sequence\"].values\n",
    "    poses = df[\"pos\"].values\n",
    "    refs = df[\"ref\"].values\n",
    "    alts = df[\"alt\"].values\n",
    "    labels = df[\"label\"].to_numpy(dtype=np.int8)\n",
    "\n",
    "    n = len(labels)\n",
    "    indices = np.arange(n)\n",
    "    shard_indices = indices[rank::world_size]\n",
    "    preds_shard = np.full(len(shard_indices), np.nan, dtype=np.float32)\n",
    "\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(shard_indices), batch_size):\n",
    "            batch_ids = shard_indices[i:i + batch_size]\n",
    "            batch_delta = compute_pll_diff_encoder_decoder(\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                seqs=seqs[batch_ids],\n",
    "                poses=poses[batch_ids],\n",
    "                refs=refs[batch_ids],\n",
    "                alts=alts[batch_ids],\n",
    "                max_len=max_len,\n",
    "            )\n",
    "\n",
    "            for j, delta in enumerate(batch_delta):\n",
    "                if delta is not None:\n",
    "                    preds_shard[i + j] = -float(delta)  # higher = more pathogenic\n",
    "\n",
    "            if (i % 20000) == 0:\n",
    "                print(f\"[Rank {rank}] Progress: {i}/{len(shard_indices)}\", flush=True)\n",
    "\n",
    "    if was_training:\n",
    "        model.train()\n",
    "\n",
    "    gathered_data = [None for _ in range(world_size)]\n",
    "    local_data = list(zip(\n",
    "        shard_indices.tolist(),\n",
    "        preds_shard.tolist(),\n",
    "        labels[shard_indices].tolist(),\n",
    "    ))\n",
    "    all_gather_object(gathered_data, local_data)\n",
    "\n",
    "    if rank == 0:\n",
    "        flat_preds = np.full(n, np.nan, dtype=np.float32)\n",
    "        for data in gathered_data:\n",
    "            for idx, pred, _ in data:\n",
    "                flat_preds[idx] = pred\n",
    "\n",
    "        mask = ~np.isnan(flat_preds)\n",
    "        if mask.sum() >= 10 and (labels[mask].min() != labels[mask].max()):\n",
    "            auc = roc_auc_score(labels[mask], flat_preds[mask])\n",
    "            print(f\"AUC (PLL) at step {step_id}: {auc:.4f}\", flush=True)\n",
    "\n",
    "            if log_wandb:\n",
    "                wandb.log({\n",
    "                    \"zero_shot_vep_auc_pll\": auc,\n",
    "                    \"step\": step_id,\n",
    "                    \"elapsed_hours\": (time.time() - start_time) / 3600.0,\n",
    "                })\n",
    "        else:\n",
    "            print(f\"Skipping AUC at step {step_id} due to insufficient data\", flush=True)\n",
    "\n",
    "        print(f\"[TIMER] VEP eval took {time.time() - start_time:.2f} seconds\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "roc_auc = {\"epoch\": [1, 2, 3, 4], \"auc_pll\": [0.6612, 0.6068, 0.6332, 0.6579]}\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(roc_auc[\"epoch\"], roc_auc[\"auc_pll\"], marker=\"o\")\n",
    "plt.title(\"T5 Gemma Zero Shot VEP over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"ROC-AUC\")\n",
    "# plt.ylim(0, 1)          \n",
    "plt.xticks(roc_auc[\"epoch\"])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
