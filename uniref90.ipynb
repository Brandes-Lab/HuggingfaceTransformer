{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecc84ac-56b8-4eb7-8c89-1f8c75e7b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ab6f73-5984-4c19-b34a-4990c37164a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 184146434 examples [00:20, 8911737.66 examples/s] \n"
     ]
    }
   ],
   "source": [
    "meta = load_dataset(\"parquet\", \n",
    "                    data_files=\"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63674a25-bd53-457c-b275-885b049c972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files=\"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\",\n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b507972-76a7-4b36-b243-ce2e4d11c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files=\"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\",\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce55da9-92fe-4a8e-8685-f63221da97bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 184146434 examples [00:18, 9966633.86 examples/s] \n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds = Dataset.from_parquet(\"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6185168c-0386-4c52-84cf-8c9f299d886a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['cluster_id', 'representative_id', 'member_count_xml_file', 'member_count', 'members'],\n",
      "    num_rows: 184146434\n",
      "})\n",
      "{'cluster_id': Value(dtype='string', id=None), 'representative_id': Value(dtype='string', id=None), 'member_count_xml_file': Value(dtype='int32', id=None), 'member_count': Value(dtype='int32', id=None), 'members': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files=\"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\",\n",
    "    split=\"train\",      # required if not streaming\n",
    "    streaming=False     # or just omit this arg\n",
    ")\n",
    "\n",
    "print(ds)\n",
    "print(ds.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b572d5cb-52fa-4839-85e9-327c723153fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['cluster_id', 'representative_id', 'member_count_xml_file', 'member_count', 'members'],\n",
      "    num_rows: 184146434\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from datasets import Dataset\n",
    "\n",
    "table = pq.read_table(\"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\")\n",
    "ds = Dataset(table)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cd81f91-a774-424f-9131-34b8e3fdc76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "cluster_id: string\n",
       "representative_id: string\n",
       "member_count_xml_file: int32\n",
       "member_count: int32\n",
       "members: list<element: string>\n",
       "  child 0, element: string\n",
       "----\n",
       "cluster_id: [[\"UniRef90_UPI002E2621C6\",\"UniRef90_UPI00358F51CD\",\"UniRef90_UPI00398E31D8\",\"UniRef90_A0A5A9P0L4\",\"UniRef90_A0ABD1JBH0\",...,\"UniRef90_UPI00225B580A\",\"UniRef90_UPI00254460F6\",\"UniRef90_UPI002796F535\",\"UniRef90_UPI002896634E\",\"UniRef90_UPI003D7BF59D\"],[\"UniRef90_UPI00222E980F\",\"UniRef90_UPI0024785306\",\"UniRef90_UPI0035A280ED\",\"UniRef90_UPI001B351495\",\"UniRef90_UPI00222EC2CE\",...,\"UniRef90_UPI00248289A7\",\"UniRef90_UPI0012FEA33D\",\"UniRef90_A0A8C5NYK4\",\"UniRef90_UPI0025ADAEBD\",\"UniRef90_UPI003BF9D085\"],...,[\"UniRef90_A0A3M7PZG0\",\"UniRef90_Q9BM67\",\"UniRef90_Q9BM66\",\"UniRef90_E9BBM2\",\"UniRef90_Q9BLZ4\",...,\"UniRef90_A0A0T5Z569\",\"UniRef90_D4J9Q7\",\"UniRef90_A0A6A7YBE0\",\"UniRef90_A0A0T5Z260\",\"UniRef90_A0A5C6IVY6\"],[\"UniRef90_Q725V0\",\"UniRef90_A0A4R4SIP9\",\"UniRef90_A0ABW1B1Z7\",\"UniRef90_A0A943LZD8\",\"UniRef90_A0ABV6HH89\",...,\"UniRef90_W8CWU6\",\"UniRef90_A0A1S5R4P5\",\"UniRef90_W8CWV6\",\"UniRef90_F1AU43\",\"UniRef90_K0JAJ8\"]]\n",
       "representative_id: [[\"UPI002E2621C6\",\"UPI00358F51CD\",\"UPI00398E31D8\",\"A0A5A9P0L4_9TELE\",\"A0ABD1JBH0_9TELE\",...,\"UPI00225B580A\",\"UPI00254460F6\",\"UPI002796F535\",\"UPI002896634E\",\"UPI003D7BF59D\"],[\"UPI00222E980F\",\"UPI0024785306\",\"UPI0035A280ED\",\"UPI001B351495\",\"UPI00222EC2CE\",...,\"UPI00248289A7\",\"UPI0012FEA33D\",\"A0A8C5NYK4_JACJA\",\"UPI0025ADAEBD\",\"UPI003BF9D085\"],...,[\"A0A3M7PZG0_BRAPC\",\"Q9BM67_BRAPC\",\"Q9BM66_BRAPC\",\"E9BBM2_LEIDO\",\"Q9BLZ4_ADIVA\",...,\"A0A0T5Z569_9GAMM\",\"D4J9Q7_9FIRM\",\"A0A6A7YBE0_9HYPH\",\"A0A0T5Z260_9GAMM\",\"A0A5C6IVY6_9ACTN\"],[\"Q725V0_NITV2\",\"A0A4R4SIP9_9ACTN\",\"A0ABW1B1Z7_9ACTN\",\"A0A943LZD8_STRVE\",\"A0ABV6HH89_9SPHI\",...,\"W8CWU6_HV1\",\"A0A1S5R4P5_HV1\",\"W8CWV6_HV1\",\"F1AU43_9RETR\",\"K0JAJ8_HV1\"]]\n",
       "member_count_xml_file: [[1,1,1,1,1,...,1,1,1,3,17],[1,2,1,24,1,...,1,1,5,1,17],...,[1,1,1,1,1,...,1,1,1,1,1],[1,1,1,1,1,...,1,1,1,1,1]]\n",
       "member_count: [[1,1,1,1,1,...,1,1,1,3,17],[1,2,1,24,1,...,1,1,5,1,17],...,[1,1,1,1,1,...,1,1,1,1,1],[1,1,1,1,1,...,1,1,1,1,1]]\n",
       "members: [[[],[],...,[\"UPI001E2D841F\",\"UPI00117FD49D\"],[\"UPI003D7B8CDB\",\"UPI003D7978EC\",\"UPI003D7AC66D\",\"UPI003D792C38\",\"UPI003D7A1F94\",...,\"UPI003D78C3B4\",\"UPI003D7A3140\",\"UPI003D794833\",\"UPI003D7B55EB\",\"UPI003D78CC4B\"]],[[],[\"UPI00247AFB57\"],...,[],[\"UPI0028C4FAB0\",\"UPI002FC3901D\",\"UPI003B27D44B\",\"UPI0028C3F07B\",\"UPI003BFA1CEA\",...,\"UPI0028C494C7\",\"UPI002FC2F640\",\"UPI003B27EEB1\",\"UPI003B2892C2\",\"UPI003B2830F9\"]],...,[[],[],...,[],[]],[[],[],...,[],[]]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "table = pq.read_table(\"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51e635b-0053-4ec7-8478-6dfc0ee9ff69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184146434"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq.read_metadata(\"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\").num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e86bba-084d-4e02-b790-0263da0f4661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_id: string\n",
       "representative_id: string\n",
       "member_count_xml_file: int32\n",
       "member_count: int32\n",
       "members: list<element: string>\n",
       "  child 0, element: string"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84ef186a-52e4-4263-92f3-a500e1241348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClusterID</th>\n",
       "      <th>RepresentativeID</th>\n",
       "      <th>member_count_xml_file</th>\n",
       "      <th>member_count</th>\n",
       "      <th>MemberIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UniRef90_UPI002E2621C6</td>\n",
       "      <td>UPI002E2621C6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UniRef90_UPI00358F51CD</td>\n",
       "      <td>UPI00358F51CD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UniRef90_UPI00398E31D8</td>\n",
       "      <td>UPI00398E31D8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UniRef90_A0A5A9P0L4</td>\n",
       "      <td>A0A5A9P0L4_9TELE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UniRef90_A0ABD1JBH0</td>\n",
       "      <td>A0ABD1JBH0_9TELE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>UniRef90_A0A6P8RG45</td>\n",
       "      <td>A0A6P8RG45_GEOSA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>UniRef90_UPI003D69693D</td>\n",
       "      <td>UPI003D69693D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UniRef90_UPI003EBDD6D2</td>\n",
       "      <td>UPI003EBDD6D2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>UPI003EBC14C6,UPI003EB9A168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>UniRef90_A0A1V4K6M4</td>\n",
       "      <td>A0A1V4K6M4_PATFA</td>\n",
       "      <td>562</td>\n",
       "      <td>562</td>\n",
       "      <td>A0A7K4RU14_COLPI,A0A7L4G2H3_9COLU,A0A094KAD8_A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>UniRef90_UPI003AB6E641</td>\n",
       "      <td>UPI003AB6E641</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ClusterID  RepresentativeID  member_count_xml_file  \\\n",
       "0   UniRef90_UPI002E2621C6     UPI002E2621C6                      1   \n",
       "1   UniRef90_UPI00358F51CD     UPI00358F51CD                      1   \n",
       "2   UniRef90_UPI00398E31D8     UPI00398E31D8                      1   \n",
       "3      UniRef90_A0A5A9P0L4  A0A5A9P0L4_9TELE                      1   \n",
       "4      UniRef90_A0ABD1JBH0  A0ABD1JBH0_9TELE                      1   \n",
       "..                     ...               ...                    ...   \n",
       "95     UniRef90_A0A6P8RG45  A0A6P8RG45_GEOSA                      1   \n",
       "96  UniRef90_UPI003D69693D     UPI003D69693D                      1   \n",
       "97  UniRef90_UPI003EBDD6D2     UPI003EBDD6D2                      3   \n",
       "98     UniRef90_A0A1V4K6M4  A0A1V4K6M4_PATFA                    562   \n",
       "99  UniRef90_UPI003AB6E641     UPI003AB6E641                      1   \n",
       "\n",
       "    member_count                                          MemberIDs  \n",
       "0              1                                                NaN  \n",
       "1              1                                                NaN  \n",
       "2              1                                                NaN  \n",
       "3              1                                                NaN  \n",
       "4              1                                                NaN  \n",
       "..           ...                                                ...  \n",
       "95             1                                                NaN  \n",
       "96             1                                                NaN  \n",
       "97             3                        UPI003EBC14C6,UPI003EB9A168  \n",
       "98           562  A0A7K4RU14_COLPI,A0A7L4G2H3_9COLU,A0A094KAD8_A...  \n",
       "99             1                                                NaN  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/gpfs/data/brandeslab/Data/uniref/uniref90_cluster_members.tsv\", sep=\"\\t\", nrows=100)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0563e10-8702-49e4-bd7e-a4aa1bffc1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClusterID                     UniRef90_UPI003EBDD6D2\n",
       "RepresentativeID                       UPI003EBDD6D2\n",
       "member_count_xml_file                              3\n",
       "member_count                                       3\n",
       "MemberIDs                UPI003EBC14C6,UPI003EB9A168\n",
       "Name: 97, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a6dbd03-90da-49d6-9891-d64afeb33660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: parasail in /gpfs/data/brandeslab/User/as12267/.conda/envs/huggingface_bert/lib/python3.10/site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in /gpfs/data/brandeslab/User/as12267/.conda/envs/huggingface_bert/lib/python3.10/site-packages (from parasail) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install parasail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9d4c668-6305-4436-b441-99be75104e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parasail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6c08ffe-a83c-43c4-acc0-192d8dff2c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: parasail in /gpfs/data/brandeslab/User/as12267/.conda/envs/huggingface_bert/lib/python3.10/site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in /gpfs/data/brandeslab/User/as12267/.conda/envs/huggingface_bert/lib/python3.10/site-packages (from parasail) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install parasail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aebbb846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: {'[PAD]': 0, '[UNK]': 1, '[CLS]': 2, '[SEP]': 3, '[MASK]': 4, '-': 5, 'A': 6, 'C': 7, 'D': 8, 'E': 9, 'F': 10, 'G': 11, 'H': 12, 'I': 13, 'K': 14, 'L': 15, 'M': 16, 'N': 17, 'P': 18, 'Q': 19, 'R': 20, 'S': 21, 'T': 22, 'V': 23, 'W': 24, 'Y': 25}\n",
      "'-' ID: 5\n",
      "\n",
      "Tests:\n",
      "'-' converts to: 5\n",
      "Tokenization of 'ACD-GH': {'input_ids': [6, 7, 8, 5, 11, 12], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n",
      "Decoding: A C D - G H\n",
      "Vocab size: 26\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Split\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "# Define vocabulary: ONLY standard 20 amino acids\n",
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")  # Standard 20 only\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"-\"]\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = {token: i for i, token in enumerate(special_tokens + amino_acids)}\n",
    "\n",
    "print(f\"Vocab: {vocab}\")\n",
    "print(f\"'-' ID: {vocab['-']}\")\n",
    "\n",
    "# Create tokenizer\n",
    "tokenizer = Tokenizer(WordLevel(vocab=vocab, unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Split(pattern=\"\", behavior=\"isolated\")\n",
    "\n",
    "# Wrap it\n",
    "hf_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\"\n",
    ")\n",
    "\n",
    "# Test\n",
    "print(\"\\nTests:\")\n",
    "print(\"'-' converts to:\", hf_tokenizer.convert_tokens_to_ids(\"-\"))\n",
    "print(\"Tokenization of 'ACD-GH':\", hf_tokenizer(\"ACD-GH\"))\n",
    "print(\"Decoding:\", hf_tokenizer.decode([6, 7, 8, 5, 11, 12]))\n",
    "print(\"Vocab size:\", len(hf_tokenizer))\n",
    "\n",
    "# hf_tokenizer.save_pretrained(\"phylo_char_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc2ca0c1-fd0e-4769-9676-5f70f64689d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parasail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb6a2992-b160-4b69-ba90-0f3ea138c2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/home/as12267/.conda/envs/huggingface_bert/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5196e974-04e2-4699-bf2d-24311f9cf39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpfs/home/as12267/.conda/envs/huggingface_bert/lib/python310.zip',\n",
       " '/gpfs/home/as12267/.conda/envs/huggingface_bert/lib/python3.10',\n",
       " '/gpfs/home/as12267/.conda/envs/huggingface_bert/lib/python3.10/lib-dynload',\n",
       " '/gpfs/home/as12267/.conda/envs/huggingface_bert/lib/python3.10/site-packages']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "[p for p in sys.path if \"conda\" in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64581b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_as_parameter_', '_cigar', '_traceback', '_traceback_args', 'cigar', 'end_query', 'end_ref', 'get_cigar', 'get_traceback', 'len_query', 'len_ref', 'length', 'length_col', 'length_row', 'length_table', 'matches', 'matches_col', 'matches_row', 'matches_table', 'matrix', 'pointer', 'query', 'ref', 'saturated', 'score', 'score_col', 'score_row', 'score_table', 'similar', 'similar_col', 'similar_row', 'similar_table', 'traceback']\n"
     ]
    }
   ],
   "source": [
    "import parasail\n",
    "result = parasail.nw_trace_scan_16(\"AAAA\", \"AAAA\", 5, 1, parasail.blosum62)\n",
    "\n",
    "print(dir(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73c3ba79-3bce-41a4-b363-bc8d4c636e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq1 Aligned: MKTAYIAKQRQISFVKSHFSRQLEERLGLIE\n",
      "Seq2 Aligned: MKTVYIAKRRQISFLKSHFSRQLDDRLGLIE\n"
     ]
    }
   ],
   "source": [
    "import parasail\n",
    "\n",
    "matrix = parasail.blosum62\n",
    "\n",
    "def align_pair(seq1, seq2):\n",
    "    # global Needleman–Wunsch alignment with traceback\n",
    "    result = parasail.nw_trace_scan_16(seq1, seq2, 10, 1, matrix)\n",
    "\n",
    "    # Extract the traceback object\n",
    "    tb = result.traceback\n",
    "\n",
    "    # Get aligned sequences\n",
    "    # a1 = tb.query.replace(\"-\", \"<GAP>\")\n",
    "    # a2 = tb.ref.replace(\"-\", \"<GAP>\")\n",
    "    a1 = tb.query\n",
    "    a2 = tb.ref\n",
    "\n",
    "    return a1, a2\n",
    "\n",
    "# Test sequences\n",
    "seq1 = \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIE\"\n",
    "seq2 = \"MKTVYIAKRRQISFLKSHFSRQLDDRLGLIE\"\n",
    "\n",
    "a1, a2 = align_pair(seq1, seq2)\n",
    "\n",
    "print(\"Seq1 Aligned:\", a1)\n",
    "print(\"Seq2 Aligned:\", a2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1f2edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq1 Aligned: MKTAYIAKQRQISFVKSHF--S\n",
      "Seq2 Aligned: MKTA----QRQISFVKSHFSSS\n"
     ]
    }
   ],
   "source": [
    "seq1 = \"MKTAYIAKQRQISFVKSHFS\"\n",
    "seq2 = \"MKTA---QRQISFVKSHFSSS\"\n",
    "\n",
    "a1, a2 = align_pair(seq1, seq2)\n",
    "\n",
    "print(\"Seq1 Aligned:\", a1)\n",
    "print(\"Seq2 Aligned:\", a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0b1963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    PreTrainedTokenizerFast,\n",
    ")\n",
    "\n",
    "class PhyloTokenizerLoader:\n",
    "    def __init__(self, tokenizer_path):\n",
    "        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n",
    "    \n",
    "    def encode(self, aligned_seq1, aligned_seq2):\n",
    "        inputs = self.tokenizer(\n",
    "            aligned_seq2,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "        labels = self.tokenizer(\n",
    "            aligned_seq1,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "        return{\n",
    "            \"input_ids\": inputs[\"input_ids\"],\n",
    "            \"labels\": labels[\"input_ids\"], \n",
    "            \"attention_mask\": inputs[\"attention_mask\"]\n",
    "        }\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.tokenizer(*args, **kwargs)\n",
    "\n",
    "# Set breakpoint inside encode() method\n",
    "# Then run this:\n",
    "phylo_tokenizer = PhyloTokenizerLoader(\"phylo_char_tokenizer\")\n",
    "\n",
    "# When you call encode, debugger will pause at your breakpoint\n",
    "result = phylo_tokenizer.encode(\"ATCG\", \"ATCG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dfc63dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [6, 22, 7, 11],\n",
       " 'labels': [6, 22, 7, 11],\n",
       " 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f8d1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gLM.dataset import UniRefClusterIterableDataset\n",
    "from gLM.tokenizers import PhyloTokenizerLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8beb3dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PhyloTokenizerLoader(\"./phylo_char_tokenizer\").load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "daa9e975",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UniRefClusterIterableDataset.__init__() missing 1 required positional argument: 'index_db_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mUniRefClusterIterableDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparquet_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfasta_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/gpfs/data/brandeslab/Data/uniref/uniref100.fasta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: UniRefClusterIterableDataset.__init__() missing 1 required positional argument: 'index_db_path'"
     ]
    }
   ],
   "source": [
    "ds = UniRefClusterIterableDataset(\n",
    "    parquet_path=\"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\",\n",
    "    fasta_path=\"/gpfs/data/brandeslab/Data/uniref/uniref100.fasta\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=8192,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b13e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(ds):\n",
    "    print(\"Got item\", i)\n",
    "    if i == 2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from gLM.dataset import UniRefClusterIterableDataset\n",
    "from gLM.tokenizers import PhyloTokenizerLoader\n",
    "\n",
    "parquet = \"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\"\n",
    "fasta   = \"/gpfs/data/brandeslab/Data/uniref/uniref100.fasta\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tok = PhyloTokenizerLoader(\"./phylo_char_tokenizer\").load()\n",
    "\n",
    "print(\"Instantiating dataset...\")\n",
    "start = time.time()\n",
    "ds = UniRefClusterIterableDataset(\n",
    "    parquet_path=parquet,\n",
    "    fasta_path=fasta,\n",
    "    tokenizer=tok,\n",
    "    max_seq_len=8192,\n",
    ")\n",
    "print(\"Dataset constructed in\", time.time() - start, \"sec\")\n",
    "\n",
    "print(\"Fetching first item...\")\n",
    "start = time.time()\n",
    "for i, item in enumerate(ds):\n",
    "    print(\"Got first item!\")\n",
    "    break\n",
    "print(\"First item fetched in\", time.time() - start, \"sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e777ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/as12267/.conda/envs/huggingface_bert/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Fetching first item...\n",
      "REP: A0ABS9P3Y9_9GAMM MEMBERS: [] <class 'list'>\n",
      "REP: A0A835XQ69_9CHLO MEMBERS: ['A0A835XMW2_9CHLO'] <class 'list'>\n",
      "PAIR: A0A835XQ69_9CHLO A0A835XMW2_9CHLO\n",
      "REP: UPI000C86E4D3 MEMBERS: [] <class 'list'>\n",
      "REP: UPI001260CD7F MEMBERS: [] <class 'list'>\n",
      "REP: A0A2I1HB31_9GLOM MEMBERS: [] <class 'list'>\n",
      "REP: A0AAF0EAU2_9BASI MEMBERS: [] <class 'list'>\n",
      "REP: UPI002ECFBE8A MEMBERS: [] <class 'list'>\n",
      "REP: UPI0002491D06 MEMBERS: [] <class 'list'>\n",
      "REP: UPI002625D505 MEMBERS: [] <class 'list'>\n",
      "REP: A0A917ZIC9_9GAMM MEMBERS: [] <class 'list'>\n",
      "REP: UPI00188B8639 MEMBERS: [] <class 'list'>\n",
      "REP: UPI003216E2CD MEMBERS: [] <class 'list'>\n",
      "REP: A0A1R1K1Z6_ALCXX MEMBERS: ['UPI0029A3963B', 'UPI0005F94960'] <class 'list'>\n",
      "PAIR: UPI0005F94960 A0A1R1K1Z6_ALCXX\n",
      "REP: A0ABU7LKA1_9NOCA MEMBERS: ['UPI000B257CD9', 'UPI00364A542B'] <class 'list'>\n",
      "PAIR: UPI000B257CD9 A0ABU7LKA1_9NOCA\n",
      "REP: UPI00112C5A48 MEMBERS: [] <class 'list'>\n",
      "REP: A0A1I2CAG8_9RHOB MEMBERS: [] <class 'list'>\n",
      "REP: A0A386KA30_9CAUD MEMBERS: [] <class 'list'>\n",
      "REP: A0AA38XHM7_9EURO MEMBERS: [] <class 'list'>\n",
      "REP: UPI003D9F7772 MEMBERS: ['UPI003D9DFE4C', 'UPI003D9F29E3', 'UPI003D9DF066', 'UPI003D9DECA5', 'UPI003D9E7CE5', 'UPI003D9DCD8F', 'UPI003D9F0598', 'UPI003D9EA93F', 'UPI003D9EF4F1', 'UPI003D9F45C3', 'UPI003D9E7C5D', 'UPI003D9F602A', 'UPI003D9DF05F', 'UPI003D9E0940', 'UPI003D9E8C64', 'UPI003D9F0081', 'UPI003D9EBEA1', 'UPI003D9F5A30', 'UPI003D9F333C'] <class 'list'>\n",
      "PAIR: UPI003D9F5A30 UPI003D9DECA5\n",
      "REP: A0ABP9UC87_9DEIO MEMBERS: ['UPI0031E9DB90'] <class 'list'>\n",
      "PAIR: A0ABP9UC87_9DEIO UPI0031E9DB90\n",
      "REP: UPI0036289435 MEMBERS: [] <class 'list'>\n",
      "REP: A0A2P5Y146_GOSBA MEMBERS: [] <class 'list'>\n",
      "REP: UPI00187BD009 MEMBERS: ['UPI00187CD83C', 'UPI00187C5C20', 'UPI00187C9A69', 'UPI00187C4E25'] <class 'list'>\n",
      "PAIR: UPI00187C9A69 UPI00187C5C20\n",
      "SEQ1: MSAWQVWEKGQAPGSWRTRPQQQHPLDTPRPRFDIAQMHTARADRLEKCMSSMQMGTQMVKLRGGSKGLVRFFYLDEHKSCIRWRPSRKNEKAKISIDSIREVCEGKQSEIFQRYSEGSFNPNCCFSLYYGEHMESLDLVSSTGEEARTWITGLKYLMAGISDEDSLAKRQRTRDQWLKQTFTEADKNGDGSLSISEVLQLLHKLNVNLPRQKVKQMFKEADTDDNQGTLGFEEFCSFYKMMSTRRDLYLLMLTYSNLKDHLDTDNLARFLETEQKMTKVTKDHCLEIINKFEPCSENQKQGVLGIDGFTNYMRSPAGDIFNPQHYNVNQDMTQPLCNYFIASSHNTYLMGDQLMSQSRVDMYAWVLQAGCRCVEVDCWDGQDGEPIVHHGYTLTSKILFKDVIETINKYAFVKNDYPVILSIENHCSVPQQKKMAQYLIEILGDKLDLSNIKADESGWLPSPETLRGKILVKGKKLPPNIDENAEEGDVSDEDSADEMEDDCKLMNGDTSANRKQVENMAKKKLDNLMKESKIRDREDPDSFTIAALPPAGKPTDKTGSKGKSEDGTDTADEANPSSNKRTGRSFIGSFSKRKQKKTSKLKKTSSFEDTDTDQESTSSTSRAPLHHSKKKKTMKLSRALSDLVKYTRSVGLYDIEAQANCSWQVSSLSETKAHQVMQQKASSFIHFNQQQLSRIYPSSYRVDSSNFNPQPFWNAGCQLVALNYQSEGRVLQLNRAKFYSNGNCGYILKPTCMCEGDFNPNLEDPLPGQMKKQLVLKVISGQQLPKPKDSMLGDRGEIIDPFVEVEIIGLPVDCCKEQTRVVDDNGFNPMWEETLVFTVHMPELALVRFLVWDHDPIGQDFIGQRTIAFNSMMPGYRHVYLEGMEEASVFVHVAVNDITGKARTASGIKGLFHRNPKQASLDSHAAVQHSRKHPFGAHLLRRTASAPTKGQPKIKKGFPEIAIDTKDYSSEGASEEPDSEDKASTATSQQPTSPLHHNGDTLASHQTKGPWDHPDTNGAFHPEKGKDCSTVQRPAPPFLALNSEDPRNTHVICSVSTPGKSLSLHQSSSAPLHSASTAINTDPPLTVPSNGVVDSPIKVSRDPKKPPTLSTTTSSTLMNPVEKTGPSQSAQNIETYRSKHSFMEHMQNQKQNLETLTHKKNDPADLKFDRRTEPCAAACVSTGTPQVPAADIAQTRRALFSSTPVRRTKSEGHVQVAQSAVPEVCTDATMNDRLWSKLEPGSHRDSMSSSSSISSSDTVIDLSLPNLARKSLTSLHTAGSTCDPPWVNCRRSALVSYDALRVSKSKSNPNLQQHECPKDELKPRPLQLPKEDTMDSPSRLTQRRHTWSRLYMEGLKQSSASRPSSAATTPTTTASLSKSLGDLTSDDISCNFDSKYRSISRSFIVRPTREQIHKGSSLKSRPSSNLTEQLRKLTNVEPLTASDFAHENRPRESQEETVDETLVRRTSSRSQSRVRYIANRAKKAQERQRLQGLIQGRSASFSLTGSIGDGSSASPIEERGNPEGACCVAQSPCTSLDLLSQLTPLGTPSPRQSQSSPDPENSEVFFMLKL\n",
      "Len SEQ1: 1570\n",
      "SEQ2: MDSVAARMAMVTDSPNLSLRSRTTMTTDGDSFVSSSSLPCSHFLSANVINVVEKCMSSMQMGTQMVKLRGGSKGLVRFFYLDEHKSCIRWRPSRKNEKAKISIDSIREVCEGKQSEIFQRYSEGSFNPNCCFSLYYGEHMESLDLVSSTGEEARTWITGLKYLMAGISDEDSLAKRQRTRDQWLKQTFTEADKNGDGSLSISEVLQLLHKLNVNLPRQKVKQMFKEADTDDNQGTLGFEEFCSFYKMMSTRRDLYLLMLTYSNLKDHLDTDNLARFLETEQKMTKVTKDHCLEIINKFEPCSENQKQGVLGIDGFTNYMRSPAGDIFNPQHYNVNQDMTQPLCNYFIASSHNTYLMGDQLMSQSRVDMYAWVLQAGCRCVEVDCWDGQDGEPIVHHGYTLTSKILFKDVIETINKYAFVKNDYPVILSIENHCSVPQQKKMAQYLIEILGDKLDLSNIKADESGWLPSPETLRGKILVKGKKLPPNIDENAEEGDVSDEDSADEMEDDCKLMNGDTSANRKQVENMAKKKLDNLMKESKIRDREDPDSFTIAALPPAGKPTDKTGSKGKSEDGTDTADEANPSSNKRTGRSFIGSFSKRKKKTSKLKKTSSFEDTDTDQESTSSTSRAPLHHSKKKKTMKLSRALSDLVKYTRSVGLYDIEAQANCSWQVSSLSETKAHQVMQQKASSFIHFNQQQLSRIYPSSYRVDSSNFNPQPFWNAGCQLVALNYQSEGRVLQLNRAKFYSNGNCGYILKPTCMCEGDFNPNLEDPLPGQMKKQLVLKVISGQQLPKPKDSMLGDRGEIIDPFVEVEIIGLPVDCCKEQTRVVDDNGFNPMWEETLVFTVHMPELALVRFLVWDHDPIGQDFIGQRTIAFNSMMPGYRHVYLEGMEEASVFVHVAVNDITGKARTASGIKGLFHRNPKQASLDSHAAVQHSRKHPFGAHLLRRTASAPTKGQPKIKKGFPEIAIDTKDYSSEGASEEPDSEDKASTATSQQPTSPLHHNGDTLASHQTKGPWDHPDTNGAFHPEKGKDCSTVQRPAPPFLALNSEDPRNTHVICSVSTPGKSLSLHQSSSAPLHSASTAINTDPPLTVPSNGVVDSPIKVSRDPKKPPTLSTTTSSTLMNPVEKTGPSQSAQNIETYRSKHSFMEHMQNQKQNLETLTHKKNDPADLKFDRRTEPCAAACVSTGTPQVPAADIAQTRRALFSSTPVRRTKSEGHVQVAQSAVPEVCTDATMNDRLWSKLEPGSHRDSMSSSSSISSSDTVIDLSLPNLARKSLTSLHTAGSTCDPPWVNCRRSALVSYDALRVSKSKSNPNLQQHECPKDELKPRPLQLPKEDTMDSPSRLTQRRHTWSRLYMEGLKQSSASRPSSAATTPTTTASLSKSLGDLTSDDISCNFDSKYRSISRSFIVRPTREQIHKGSSLKSRPSSNLTEQLRKLTNVEPLTASDFAHENRPRESQEETVDETLVRRTSSRSQSRVRYIANRAKKAQERQRLQGLIQGRSASFSLTGSIGDGSSASPIEERGNPEGACCVAQSPCTSLDLLSQLTPLGTPSPRQSQSSPDPENSEVFFMLKL\n",
      "Len SEQ2: 1575\n",
      "ALN1: MS--AWQVWEKGQAPG-SWRTRPQQQHPLDTPRPRFDIAQMHTARADRL---EKCMSSMQMGTQMVKLRGGSKGLVRFFYLDEHKSCIRWRPSRKNEKAKISIDSIREVCEGKQSEIFQRYSEGSFNPNCCFSLYYGEHMESLDLVSSTGEEARTWITGLKYLMAGISDEDSLAKRQRTRDQWLKQTFTEADKNGDGSLSISEVLQLLHKLNVNLPRQKVKQMFKEADTDDNQGTLGFEEFCSFYKMMSTRRDLYLLMLTYSNLKDHLDTDNLARFLETEQKMTKVTKDHCLEIINKFEPCSENQKQGVLGIDGFTNYMRSPAGDIFNPQHYNVNQDMTQPLCNYFIASSHNTYLMGDQLMSQSRVDMYAWVLQAGCRCVEVDCWDGQDGEPIVHHGYTLTSKILFKDVIETINKYAFVKNDYPVILSIENHCSVPQQKKMAQYLIEILGDKLDLSNIKADESGWLPSPETLRGKILVKGKKLPPNIDENAEEGDVSDEDSADEMEDDCKLMNGDTSANRKQVENMAKKKLDNLMKESKIRDREDPDSFTIAALPPAGKPTDKTGSKGKSEDGTDTADEANPSSNKRTGRSFIGSFSKRKQKKTSKLKKTSSFEDTDTDQESTSSTSRAPLHHSKKKKTMKLSRALSDLVKYTRSVGLYDIEAQANCSWQVSSLSETKAHQVMQQKASSFIHFNQQQLSRIYPSSYRVDSSNFNPQPFWNAGCQLVALNYQSEGRVLQLNRAKFYSNGNCGYILKPTCMCEGDFNPNLEDPLPGQMKKQLVLKVISGQQLPKPKDSMLGDRGEIIDPFVEVEIIGLPVDCCKEQTRVVDDNGFNPMWEETLVFTVHMPELALVRFLVWDHDPIGQDFIGQRTIAFNSMMPGYRHVYLEGMEEASVFVHVAVNDITGKARTASGIKGLFHRNPKQASLDSHAAVQHSRKHPFGAHLLRRTASAPTKGQPKIKKGFPEIAIDTKDYSSEGASEEPDSEDKASTATSQQPTSPLHHNGDTLASHQTKGPWDHPDTNGAFHPEKGKDCSTVQRPAPPFLALNSEDPRNTHVICSVSTPGKSLSLHQSSSAPLHSASTAINTDPPLTVPSNGVVDSPIKVSRDPKKPPTLSTTTSSTLMNPVEKTGPSQSAQNIETYRSKHSFMEHMQNQKQNLETLTHKKNDPADLKFDRRTEPCAAACVSTGTPQVPAADIAQTRRALFSSTPVRRTKSEGHVQVAQSAVPEVCTDATMNDRLWSKLEPGSHRDSMSSSSSISSSDTVIDLSLPNLARKSLTSLHTAGSTCDPPWVNCRRSALVSYDALRVSKSKSNPNLQQHECPKDELKPRPLQLPKEDTMDSPSRLTQRRHTWSRLYMEGLKQSSASRPSSAATTPTTTASLSKSLGDLTSDDISCNFDSKYRSISRSFIVRPTREQIHKGSSLKSRPSSNLTEQLRKLTNVEPLTASDFAHENRPRESQEETVDETLVRRTSSRSQSRVRYIANRAKKAQERQRLQGLIQGRSASFSLTGSIGDGSSASPIEERGNPEGACCVAQSPCTSLDLLSQLTPLGTPSPRQSQSSPDPENSEVFFMLKL\n",
      "Len ALN1: 1576\n",
      "ALN2: MDSVAARMAMVTDSPNLSLRSRTTMTTDGDSFVSSSSLPCSHFLSANVINVVEKCMSSMQMGTQMVKLRGGSKGLVRFFYLDEHKSCIRWRPSRKNEKAKISIDSIREVCEGKQSEIFQRYSEGSFNPNCCFSLYYGEHMESLDLVSSTGEEARTWITGLKYLMAGISDEDSLAKRQRTRDQWLKQTFTEADKNGDGSLSISEVLQLLHKLNVNLPRQKVKQMFKEADTDDNQGTLGFEEFCSFYKMMSTRRDLYLLMLTYSNLKDHLDTDNLARFLETEQKMTKVTKDHCLEIINKFEPCSENQKQGVLGIDGFTNYMRSPAGDIFNPQHYNVNQDMTQPLCNYFIASSHNTYLMGDQLMSQSRVDMYAWVLQAGCRCVEVDCWDGQDGEPIVHHGYTLTSKILFKDVIETINKYAFVKNDYPVILSIENHCSVPQQKKMAQYLIEILGDKLDLSNIKADESGWLPSPETLRGKILVKGKKLPPNIDENAEEGDVSDEDSADEMEDDCKLMNGDTSANRKQVENMAKKKLDNLMKESKIRDREDPDSFTIAALPPAGKPTDKTGSKGKSEDGTDTADEANPSSNKRTGRSFIGSFSKRK-KKTSKLKKTSSFEDTDTDQESTSSTSRAPLHHSKKKKTMKLSRALSDLVKYTRSVGLYDIEAQANCSWQVSSLSETKAHQVMQQKASSFIHFNQQQLSRIYPSSYRVDSSNFNPQPFWNAGCQLVALNYQSEGRVLQLNRAKFYSNGNCGYILKPTCMCEGDFNPNLEDPLPGQMKKQLVLKVISGQQLPKPKDSMLGDRGEIIDPFVEVEIIGLPVDCCKEQTRVVDDNGFNPMWEETLVFTVHMPELALVRFLVWDHDPIGQDFIGQRTIAFNSMMPGYRHVYLEGMEEASVFVHVAVNDITGKARTASGIKGLFHRNPKQASLDSHAAVQHSRKHPFGAHLLRRTASAPTKGQPKIKKGFPEIAIDTKDYSSEGASEEPDSEDKASTATSQQPTSPLHHNGDTLASHQTKGPWDHPDTNGAFHPEKGKDCSTVQRPAPPFLALNSEDPRNTHVICSVSTPGKSLSLHQSSSAPLHSASTAINTDPPLTVPSNGVVDSPIKVSRDPKKPPTLSTTTSSTLMNPVEKTGPSQSAQNIETYRSKHSFMEHMQNQKQNLETLTHKKNDPADLKFDRRTEPCAAACVSTGTPQVPAADIAQTRRALFSSTPVRRTKSEGHVQVAQSAVPEVCTDATMNDRLWSKLEPGSHRDSMSSSSSISSSDTVIDLSLPNLARKSLTSLHTAGSTCDPPWVNCRRSALVSYDALRVSKSKSNPNLQQHECPKDELKPRPLQLPKEDTMDSPSRLTQRRHTWSRLYMEGLKQSSASRPSSAATTPTTTASLSKSLGDLTSDDISCNFDSKYRSISRSFIVRPTREQIHKGSSLKSRPSSNLTEQLRKLTNVEPLTASDFAHENRPRESQEETVDETLVRRTSSRSQSRVRYIANRAKKAQERQRLQGLIQGRSASFSLTGSIGDGSSASPIEERGNPEGACCVAQSPCTSLDLLSQLTPLGTPSPRQSQSSPDPENSEVFFMLKL\n",
      "Len ALN2: 1576\n",
      "TRUNC1: MS--AWQVWEKGQAPG-SWRTRPQQQHPLDTPRPRFDIAQMHTARADRL---EKCMSSMQMGTQMVKLRGGSKGLVRFFYLDEHKSCIRWRPSRKNEKAKISIDSIREVCEGKQSEIFQRYSEGSFNPNCCFSLYYGEHMESLDLVSSTGEEARTWITGLKYLMAGISDEDSLAKRQRTRDQWLKQTFTEADKNGDGSLSISEVLQLLHKLNVNLPRQKVKQMFKEADTDDNQGTLGFEEFCSFYKMMSTRRDLYLLMLTYSNLKDHLDTDNLARFLETEQKMTKVTKDHCLEIINKFEPCSENQKQGVLGIDGFTNYMRSPAGDIFNPQHYNVNQDMTQPLCNYFIASSHNTYLMGDQLMSQSRVDMYAWVLQAGCRCVEVDCWDGQDGEPIVHHGYTLTSKILFKDVIETINKYAFVKNDYPVILSIENHCSVPQQKKMAQYLIEILGDKLDLSNIKADESGWLPSPETLRGKILVKGKKLPPNIDENAEEGDVSDEDSADEMEDDCKLMNGDTSANRKQVENMAKKKLDNLMKESKIRDREDPDSFTIAALPPAGKPTDKTGSKGKSEDGTDTADEANPSSNKRTGRSFIGSFSKRKQKKTSKLKKTSSFEDTDTDQESTSSTSRAPLHHSKKKKTMKLSRALSDLVKYTRSVGLYDIEAQANCSWQVSSLSETKAHQVMQQKASSFIHFNQQQLSRIYPSSYRVDSSNFNPQPFWNAGCQLVALNYQSEGRVLQLNRAKFYSNGNCGYILKPTCMCEGDFNPNLEDPLPGQMKKQLVLKVISGQQLPKPKDSMLGDRGEIIDPFVEVEIIGLPVDCCKEQTRVVDDNGFNPMWEETLVFTVHMPELALVRFLVWDHDPIGQDFIGQRTIAFNSMMPGYRHVYLEGMEEASVFVHVAVNDITGKARTASGIKGLFHRNPKQASLDSHAAVQHSRKHPFGAHLLRRTASAPTKGQPKIKKGFPEIAIDTKDYSSEGASEEPDSEDKASTATSQQPTSPLHHNGDTLASHQTKGPWDHPDTNGAFHPEKGKDCSTVQRPAPPFLALNSEDPRNTHVICSVSTPGKSLSLHQSSSAPLHSASTAINTDPPLTVPSNGVVDSPIKVSRDPKKPPTLSTTTSSTLMNPVEKTGPSQSAQNIETYRSKHSFMEHMQNQKQNLETLTHKKNDPADLKFDRRTEPCAAACVSTGTPQVPAADIAQTRRALFSSTPVRRTKSEGHVQVAQSAVPEVCTDATMNDRLWSKLEPGSHRDSMSSSSSISSSDTVIDLSLPNLARKSLTSLHTAGSTCDPPWVNCRRSALVSYDALRVSKSKSNPNLQQHECPKDELKPRPLQLPKEDTMDSPSRLTQRRHTWSRLYMEGLKQSSASRPSSAATTPTTTASLSKSLGDLTSDDISCNFDSKYRSISRSFIVRPTREQIHKGSSLKSRPSSNLTEQLRKLTNVEPLTASDFAHENRPRESQEETVDETLVRRTSSRSQSRVRYIANRAKKAQERQRLQGLIQGRSASFSLTGSIGDGSSASPIEERGNPEGACCVAQSPCTSLDLLSQLTPLGTPSPRQSQSSPDPENSEVFFMLKL\n",
      "Len TRUNC1: 1576\n",
      "TRUNC2: MDSVAARMAMVTDSPNLSLRSRTTMTTDGDSFVSSSSLPCSHFLSANVINVVEKCMSSMQMGTQMVKLRGGSKGLVRFFYLDEHKSCIRWRPSRKNEKAKISIDSIREVCEGKQSEIFQRYSEGSFNPNCCFSLYYGEHMESLDLVSSTGEEARTWITGLKYLMAGISDEDSLAKRQRTRDQWLKQTFTEADKNGDGSLSISEVLQLLHKLNVNLPRQKVKQMFKEADTDDNQGTLGFEEFCSFYKMMSTRRDLYLLMLTYSNLKDHLDTDNLARFLETEQKMTKVTKDHCLEIINKFEPCSENQKQGVLGIDGFTNYMRSPAGDIFNPQHYNVNQDMTQPLCNYFIASSHNTYLMGDQLMSQSRVDMYAWVLQAGCRCVEVDCWDGQDGEPIVHHGYTLTSKILFKDVIETINKYAFVKNDYPVILSIENHCSVPQQKKMAQYLIEILGDKLDLSNIKADESGWLPSPETLRGKILVKGKKLPPNIDENAEEGDVSDEDSADEMEDDCKLMNGDTSANRKQVENMAKKKLDNLMKESKIRDREDPDSFTIAALPPAGKPTDKTGSKGKSEDGTDTADEANPSSNKRTGRSFIGSFSKRK-KKTSKLKKTSSFEDTDTDQESTSSTSRAPLHHSKKKKTMKLSRALSDLVKYTRSVGLYDIEAQANCSWQVSSLSETKAHQVMQQKASSFIHFNQQQLSRIYPSSYRVDSSNFNPQPFWNAGCQLVALNYQSEGRVLQLNRAKFYSNGNCGYILKPTCMCEGDFNPNLEDPLPGQMKKQLVLKVISGQQLPKPKDSMLGDRGEIIDPFVEVEIIGLPVDCCKEQTRVVDDNGFNPMWEETLVFTVHMPELALVRFLVWDHDPIGQDFIGQRTIAFNSMMPGYRHVYLEGMEEASVFVHVAVNDITGKARTASGIKGLFHRNPKQASLDSHAAVQHSRKHPFGAHLLRRTASAPTKGQPKIKKGFPEIAIDTKDYSSEGASEEPDSEDKASTATSQQPTSPLHHNGDTLASHQTKGPWDHPDTNGAFHPEKGKDCSTVQRPAPPFLALNSEDPRNTHVICSVSTPGKSLSLHQSSSAPLHSASTAINTDPPLTVPSNGVVDSPIKVSRDPKKPPTLSTTTSSTLMNPVEKTGPSQSAQNIETYRSKHSFMEHMQNQKQNLETLTHKKNDPADLKFDRRTEPCAAACVSTGTPQVPAADIAQTRRALFSSTPVRRTKSEGHVQVAQSAVPEVCTDATMNDRLWSKLEPGSHRDSMSSSSSISSSDTVIDLSLPNLARKSLTSLHTAGSTCDPPWVNCRRSALVSYDALRVSKSKSNPNLQQHECPKDELKPRPLQLPKEDTMDSPSRLTQRRHTWSRLYMEGLKQSSASRPSSAATTPTTTASLSKSLGDLTSDDISCNFDSKYRSISRSFIVRPTREQIHKGSSLKSRPSSNLTEQLRKLTNVEPLTASDFAHENRPRESQEETVDETLVRRTSSRSQSRVRYIANRAKKAQERQRLQGLIQGRSASFSLTGSIGDGSSASPIEERGNPEGACCVAQSPCTSLDLLSQLTPLGTPSPRQSQSSPDPENSEVFFMLKL\n",
      "Len TRUNC2: 1576\n",
      "PID: 97.20812182741116\n",
      "Success!\n",
      "dict_keys(['input_ids', 'labels', 'attention_mask', 'percent_identity'])\n"
     ]
    }
   ],
   "source": [
    "from gLM.dataset import UniRefClusterIterableDataset\n",
    "from gLM.tokenizers import PhyloTokenizerLoader\n",
    "import time\n",
    "\n",
    "parquet = \"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\"\n",
    "fasta   = \"/gpfs/data/brandeslab/Data/uniref/uniref100.fasta\"\n",
    "index_db = \"/gpfs/data/brandeslab/User/as12267/uniref100.idx\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tok = PhyloTokenizerLoader(\"./phylo_char_tokenizer\")\n",
    "\n",
    "ds = UniRefClusterIterableDataset(\n",
    "    parquet_path=parquet,\n",
    "    index_db_path=index_db,\n",
    "    fasta_path=fasta,\n",
    "    tokenizer=tok,\n",
    "    max_seq_len=8192,\n",
    ")\n",
    "\n",
    "print(\"Fetching first item...\")\n",
    "for i, x in enumerate(ds):\n",
    "    print(\"Success!\")\n",
    "    print(x.keys())\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27ade34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "------BATCH START------\n",
      "SEQ LEN: 236\n",
      "SEQ LEN: 387\n",
      "SEQ LEN: 344\n",
      "SEQ LEN: 121\n",
      "-------BATCH END-------\n",
      "input_ids shape: torch.Size([4, 387])\n",
      "labels shape: torch.Size([4, 387])\n",
      "attention_mask shape: torch.Size([4, 387])\n",
      "percent_identity: tensor([91.9492, 91.2145, 98.2558, 98.3471])\n"
     ]
    }
   ],
   "source": [
    "from gLM.dataset import UniRefClusterIterableDataset\n",
    "from gLM.tokenizers import PhyloTokenizerLoader\n",
    "from gLM.collator import SequencePairCollator\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "parquet = \"/gpfs/data/brandeslab/Data/uniref/uniref90_clusters.parquet\"\n",
    "fasta   = \"/gpfs/data/brandeslab/Data/uniref/uniref100.fasta\"\n",
    "index_db = \"/gpfs/data/brandeslab/User/as12267/uniref100.idx\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tok = PhyloTokenizerLoader(\"./phylo_char_tokenizer\")\n",
    "\n",
    "ds = UniRefClusterIterableDataset(\n",
    "    parquet_path=parquet,\n",
    "    index_db_path=index_db,\n",
    "    fasta_path=fasta,\n",
    "    tokenizer=tok,\n",
    "    max_seq_len=8192,\n",
    ")\n",
    "\n",
    "\n",
    "collator = SequencePairCollator(pad_id=tok.tokenizer.pad_token_id)\n",
    "\n",
    "loader = DataLoader(\n",
    "    ds, \n",
    "    batch_size=4, \n",
    "    collate_fn=collator,\n",
    "    num_workers=0\n",
    "\n",
    ")\n",
    "batch = next(iter(loader))\n",
    "\n",
    "print(\"input_ids shape:\", batch[\"input_ids\"].shape)\n",
    "print(\"labels shape:\", batch[\"labels\"].shape)\n",
    "print(\"attention_mask shape:\", batch[\"attention_mask\"].shape)\n",
    "print(\"percent_identity:\", batch[\"percent_identity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b617f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phylo Tokenizer loaded. GAP ID: 5\n",
      "vocab size: 26\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PhyloTokenizerLoader(\"./phylo_char_tokenizer\").load()\n",
    "pad_id = tokenizer.pad_token_id\n",
    "gap_id = tokenizer.convert_tokens_to_ids(\"-\")\n",
    "print(\"Phylo Tokenizer loaded. GAP ID:\", gap_id)\n",
    "print(f\"vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d7770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cluster_id': 'UniRef90_A0AAD2JM23', 'representative_id': 'A0AAD2JM23_9STRA', 'members': ['A0A9K3LU73_9STRA']}\n",
      "{'cluster_id': 'UniRef90_A0A2T5GHF6', 'representative_id': 'A0A2T5GHF6_9SPHN', 'members': ['UPI0011B1CF18', 'UPI00177CA10F', 'UPI00335862B2', 'UPI001783B8B9', 'UPI00178503EB', 'UPI002A6B860E']}\n",
      "{'cluster_id': 'UniRef90_A0ABD3RNB6', 'representative_id': 'A0ABD3RNB6_9LAMI', 'members': []}\n",
      "{'cluster_id': 'UniRef90_A0ABN7WPN7', 'representative_id': 'A0ABN7WPN7_GIGMA', 'members': ['A0ABN7X348_GIGMA']}\n",
      "{'cluster_id': 'UniRef90_UPI0031F96DD0', 'representative_id': 'UPI0031F96DD0', 'members': []}\n"
     ]
    }
   ],
   "source": [
    "from gLM.data_utils.uniref_cluster_sampler import RandomClusterSampler\n",
    "\n",
    "sampler = RandomClusterSampler(parquet)\n",
    "for _ in range(5):\n",
    "    cluster = sampler.sample_clusters()\n",
    "    print(cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.4\n"
     ]
    }
   ],
   "source": [
    "import parasail\n",
    "print(parasail.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2711721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created test CSV at ./test_vep_data.csv\n",
      "Using flash_attention_2 attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3720264/3008571830.py:71: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing VEP callback directly ===\n",
      "[Rank 0] Starting zero-shot VEP eval @ step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/as12267/.conda/envs/huggingface_bert/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rank 0] Progress: 0/4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# 7. Test the callback directly (without training)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Testing VEP callback directly ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m \u001b[43mvep_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_vep_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# 8. Optional: Run one training step to verify callback integration\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# print(\"\\n=== Testing callback during training ===\")\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# trainer.train()\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Test complete ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/gpfs/data/brandeslab/Project/HuggingfaceTransformer/gLM/callbacks/variant_effect.py:174\u001b[0m, in \u001b[0;36mZeroShotVEPEvaluationCallback.run_vep_eval\u001b[0;34m(self, model, step_id)\u001b[0m\n\u001b[1;32m    170\u001b[0m gathered_data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(world_size)]\n\u001b[1;32m    171\u001b[0m local_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mzip\u001b[39m(shard_indices\u001b[38;5;241m.\u001b[39mtolist(), preds_shard\u001b[38;5;241m.\u001b[39mtolist(), labels[shard_indices]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m    173\u001b[0m )\n\u001b[0;32m--> 174\u001b[0m \u001b[43mall_gather_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgathered_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    177\u001b[0m     flat_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(n, np\u001b[38;5;241m.\u001b[39mnan, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/.conda/envs/huggingface_bert/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:81\u001b[0m, in \u001b[0;36m_exception_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     83\u001b[0m         msg_dict \u001b[38;5;241m=\u001b[39m _get_msg_dict(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/huggingface_bert/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:3026\u001b[0m, in \u001b[0;36mall_gather_object\u001b[0;34m(object_list, obj, group)\u001b[0m\n\u001b[1;32m   3023\u001b[0m     _warn_not_in_group(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_gather_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 3026\u001b[0m current_device \u001b[38;5;241m=\u001b[39m \u001b[43m_get_object_coll_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3027\u001b[0m input_tensor, local_size \u001b[38;5;241m=\u001b[39m _object_to_tensor(obj, current_device, group)\n\u001b[1;32m   3029\u001b[0m \u001b[38;5;66;03m# Gather all local sizes. This is so that we can find the max size, and index\u001b[39;00m\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;66;03m# until the correct size when deserializing the tensors.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/huggingface_bert/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:791\u001b[0m, in \u001b[0;36m_get_object_coll_device\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_object_coll_device\u001b[39m(group: Optional[ProcessGroup] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    769\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03m    .. note:: This is an internal helper and does not have backward\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03m        compatibility, please use with caution.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m \n\u001b[1;32m    790\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m     group \u001b[38;5;241m=\u001b[39m group \u001b[38;5;129;01mor\u001b[39;00m \u001b[43m_get_default_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(group, ProcessGroup):\n\u001b[1;32m    794\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a Backend \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(group)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as a ProcessGroup. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis usage is deprecated since PyTorch 2.0. Please use a public API \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    797\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof PyTorch Distributed instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    798\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/huggingface_bert/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:1298\u001b[0m, in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the default process group created by init_process_group.\"\"\"\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_initialized():\n\u001b[0;32m-> 1298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1299\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault process group has not been initialized, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease make sure to call init_process_group.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1301\u001b[0m     )\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m not_none(GroupMember\u001b[38;5;241m.\u001b[39mWORLD)\n",
      "\u001b[0;31mValueError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gLM.models.protein_bert import ProteinBertModel\n",
    "from gLM.tokenizers import TokenizerLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from gLM.callbacks import ZeroShotVEPEvaluationCallback  \n",
    "\n",
    "# 1. Create a minimal test CSV with VEP data\n",
    "test_data = {\n",
    "    'sequence': [\n",
    "        'MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQDNLSGAEKAVQVKVKALPDAQFEVVHSLAKWKRQTLGQHDFSAGEGLYTHMKALRPDEDRLSLEVGQSGNDIAAYRLTDMPPTMAQQVKQPLQERAQAWADTGAATRAVLPRLCGVMNHRFQTHAAVDALRLSGAVPRTLVALLASPE',\n",
    "        'MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQDNLSGAEKAVQVKVKALPDAQFEVVHSLAKWKRQTLGQHDFSAGEGLYTHMKALRPDEDRLSLEVGQSGNDIAAYRLTDMPPTMAQQVKQPLQERAQAWADTGAATRAVLPRLCGVMNHRFQTHAAVDALRLSGAVPRTLVALLASPE',\n",
    "        'MVHLTPEEKSAVTALWGKVNVDEVGGEALGRLLVVYPWTQRFFESFGDLSTPDAVMGNPKVKAHGKKVLGAFSDGLAHLDNLKGTFATLSELHCDKLHVDPENFRLLGNVLVCVLAHHFGKEFTPPVQAAYQKVVAGVANALAHKYH',\n",
    "        'MVHLTPEEKSAVTALWGKVNVDEVGGEALGRLLVVYPWTQRFFESFGDLSTPDAVMGNPKVKAHGKKVLGAFSDGLAHLDNLKGTFATLSELHCDKLHVDPENFRLLGNVLVCVLAHHFGKEFTPPVQAAYQKVVAGVANALAHKYH',\n",
    "    ],\n",
    "    'pos': [10, 20, 15, 25],\n",
    "    'ref': ['Q', 'V', 'K', 'K'],\n",
    "    'alt': ['E', 'A', 'E', 'R'],\n",
    "    'label': [1, 0, 1, 0]  # 1 = pathogenic, 0 = benign\n",
    "}\n",
    "\n",
    "test_csv_path = './test_vep_data.csv'\n",
    "pd.DataFrame(test_data).to_csv(test_csv_path, index=False)\n",
    "print(f\"Created test CSV at {test_csv_path}\")\n",
    "\n",
    "# 2. Initialize tokenizer and model\n",
    "tokenizer = TokenizerLoader(\"./char_tokenizer\").load()\n",
    "model = ProteinBertModel(\n",
    "    vocab_size=tokenizer.vocab_size, \n",
    "    tokenizer=tokenizer, \n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").build()\n",
    "\n",
    "# 3. Create minimal training arguments (for testing, just 1 step)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./test_vep_callback\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    max_steps=1,  # Just 1 step for testing\n",
    "    logging_steps=1,\n",
    "    save_steps=1000,  # Don't save during test\n",
    "    fp16=False,  # Disable for easier debugging\n",
    "    report_to=\"none\",  # Disable wandb for testing\n",
    ")\n",
    "\n",
    "# 4. Create dummy dataset (minimal)\n",
    "class DummyDataset:\n",
    "    def __len__(self):\n",
    "        return 4\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return tokenized dummy sequences\n",
    "        seq = \"MKTAYIAKQRQISFVK\"\n",
    "        tokens = tokenizer(seq, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        return {k: v.squeeze(0) for k, v in tokens.items()}\n",
    "\n",
    "train_ds = DummyDataset()\n",
    "\n",
    "# 5. Initialize the VEP callback\n",
    "vep_callback = ZeroShotVEPEvaluationCallback(\n",
    "    tokenizer=tokenizer,\n",
    "    input_csv=test_csv_path,\n",
    "    trainer=None,  # Will be set by Trainer\n",
    "    max_len=512,  # Smaller for testing\n",
    "    eval_every_n_steps=1,  # Evaluate after every step for testing\n",
    "    batch_size=2,\n",
    "    training_type=\"phylo\",  # or \"MLM\" depending on your model\n",
    ")\n",
    "\n",
    "# 6. Create trainer with callback\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[vep_callback],\n",
    ")\n",
    "\n",
    "# 7. Test the callback directly (without training)\n",
    "print(\"\\n=== Testing VEP callback directly ===\")\n",
    "vep_callback.run_vep_eval(model, step_id=0)\n",
    "\n",
    "# 8. Optional: Run one training step to verify callback integration\n",
    "# print(\"\\n=== Testing callback during training ===\")\n",
    "# trainer.train()\n",
    "\n",
    "print(\"\\n=== Test complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20920a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
